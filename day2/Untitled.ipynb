{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e4d9e21-d72d-4842-a9ae-110b4157c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989cd193-52d1-438e-a34c-acb7a2d644f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6615384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "glass = pd.read_csv('../Cases/Glass_Identification/Glass.csv')\n",
    "X = glass.drop('Type', axis=1)\n",
    "y = glass['Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25, stratify=y)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e219fdc-0c47-4133-9e44-d8a641ac161f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       method     score\n",
      "0          l1  0.538462\n",
      "1          l2  0.538462\n",
      "2  elasticnet  0.538462\n",
      "3        None  0.538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "penalties = ['l1','l2','elasticnet',None]\n",
    "\n",
    "score = []\n",
    "\n",
    "for p in penalties:\n",
    "    lr = LogisticRegression(solver='saga', penalty=p, l1_ratio=0.5)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    score.append([p, accuracy_score(y_pred, y_test)])\n",
    "score = pd.DataFrame(score, columns=['method', 'score'])\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8875cf67-5520-4538-b723-2dedff8e093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\optimize.py:319: ConvergenceWarning: newton-cg failed to converge at loss = 0.5297977463867943. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:591: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 13. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.83848e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:197: ConvergenceWarning: lbfgs failed to converge after 87 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=87).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res, max_iter=max_iter)\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>None</td>\n",
       "      <td>0.630769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>None</td>\n",
       "      <td>0.630769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>None</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            solver penalty     score\n",
       "0              sag      l2  0.538462\n",
       "1              sag    None  0.538462\n",
       "2        newton-cg      l2  0.661538\n",
       "3        newton-cg    None  0.630769\n",
       "4  newton-cholesky      l2  0.661538\n",
       "5  newton-cholesky    None  0.630769\n",
       "6            lbfgs      l2  0.661538\n",
       "7            lbfgs    None  0.615385"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalties = ['l2',None]\n",
    "solvers = ['sag', 'newton-cg','newton-cholesky','lbfgs']\n",
    "score = []\n",
    "for s in solvers:\n",
    "    for p in penalties:\n",
    "        lr = LogisticRegression(solver=s, penalty=p)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        score.append([s, p, accuracy_score(y_pred, y_test)])\n",
    "\n",
    "score = pd.DataFrame(score, columns=['solver', 'penalty', 'score'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3fa28f-d1a6-4ca8-a9aa-ffc136f11cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6615384615384615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68        23\n",
      "           1       0.74      0.61      0.67        28\n",
      "           2       0.50      0.50      0.50         4\n",
      "           3       0.89      0.89      0.89         9\n",
      "           4       0.33      1.00      0.50         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.53      0.61      0.54        65\n",
      "weighted avg       0.73      0.66      0.69        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\dai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(glass['Type'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=25)\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg', penalty='l2')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b66e612f-a055-4a52-96d8-b0afc617d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  25.  250. 2500.] [  11.18033989  111.80339887 1118.03398875]\n",
      "         x0        x1        x2\n",
      "0 -1.341641 -1.341641 -1.341641\n",
      "1 -0.447214 -0.447214 -0.447214\n",
      "2  0.447214  0.447214  0.447214\n",
      "3  1.341641  1.341641  1.341641\n",
      "x0    0.0\n",
      "x1    0.0\n",
      "x2    0.0\n",
      "dtype: float64\n",
      "x0    1.154701\n",
      "x1    1.154701\n",
      "x2    1.154701\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[10,100,1000],\n",
    "                  [20,200,2000],\n",
    "                  [30,300,3000],\n",
    "                  [40,400,4000]])\n",
    "\n",
    "print(array.mean(axis=0), array.std(axis=0))\n",
    "\n",
    "ss = StandardScaler().set_output(transform='pandas')\n",
    "array_scaled = ss.fit_transform(array)\n",
    "\n",
    "print(array_scaled)\n",
    "print(array_scaled.mean())\n",
    "print(array_scaled.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "394b4205-a70a-4383-8ea6-7dcb43cd68ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2\n",
      "0  0.000000  0.000000  0.000000\n",
      "1  0.333333  0.333333  0.333333\n",
      "2  0.666667  0.666667  0.666667\n",
      "3  1.000000  1.000000  1.000000\n",
      "x0    0.5\n",
      "x1    0.5\n",
      "x2    0.5\n",
      "dtype: float64 x0    0.430331\n",
      "x1    0.430331\n",
      "x2    0.430331\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[10,100,1000],\n",
    "                  [20,200,2000],\n",
    "                  [30,300,3000],\n",
    "                  [40,400,4000]])\n",
    "\n",
    "mm = MinMaxScaler().set_output(transform='pandas')\n",
    "\n",
    "array_scaled = mm.fit_transform(array)\n",
    "\n",
    "print(array_scaled) # scaled values will be between 0 & 1\n",
    "\n",
    "print(array_scaled.mean(), array_scaled.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055249f6-94c5-4697-bf77-96890ec96398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- Nearest Neighbour\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d874e63-d3c6-4b34-9b82-b2a1cec6df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.957143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k     score\n",
       "0   1  0.957143\n",
       "1   2  0.933333\n",
       "2   3  0.971429\n",
       "3   4  0.961905\n",
       "4   5  0.976190\n",
       "5   6  0.952381\n",
       "6   7  0.961905\n",
       "7   8  0.961905\n",
       "8   9  0.961905\n",
       "9  10  0.961905"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv('../Cases/Wisconsin/BreastCancer.csv')\n",
    "\n",
    "X = cancer.drop(['Code', 'Class'], axis=1)\n",
    "y = cancer['Class']\n",
    "\n",
    "\n",
    "scores = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25, stratify=y)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append([i, accuracy_score(y_pred, y_test)])\n",
    "\n",
    "scores = pd.DataFrame(scores, columns=['k', 'score'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dd6e83c-bb0d-4cf4-89c3-835493661415",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scalar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m25\u001b[39m)\n\u001b[32m      8\u001b[39m ss = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m X_train_scl = \u001b[43mscalar\u001b[49m.fit_transform(X_train)\n\u001b[32m     11\u001b[39m X_test_scl = scalar.transform(X_test)\n\u001b[32m     13\u001b[39m scores = []\n",
      "\u001b[31mNameError\u001b[39m: name 'scalar' is not defined"
     ]
    }
   ],
   "source": [
    "hr = pd.read_csv('../Cases/HRAnalytics/HR_comma_sep.csv')\n",
    "\n",
    "X = hr.drop('left', axis=1)\n",
    "y = hr['left']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train_scl = scalar.fit_transform(X_train)\n",
    "X_test_scl = scalar.transform(X_test)\n",
    "\n",
    "scores = []\n",
    "for k in range(1, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scl, y_train)\n",
    "    y_pred = knn.predict(X_test_scl)\n",
    "\n",
    "    scores.append([k, accuracy_score(y_pred, y_test)])\n",
    "\n",
    "scores = pd.DataFrame(scores, columns=['k', 'score'])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a094985-2708-4769-8d35-705a4c883489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
